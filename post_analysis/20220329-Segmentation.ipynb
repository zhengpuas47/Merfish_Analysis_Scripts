{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34fa0559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7196\n"
     ]
    }
   ],
   "source": [
    "%run \"..\\..\\Startup_py3.py\"\n",
    "sys.path.append(r\"..\\..\\..\\..\\Documents\")\n",
    "\n",
    "import ImageAnalysis3 as ia\n",
    "%matplotlib notebook\n",
    "\n",
    "from ImageAnalysis3 import *\n",
    "print(os.getpid())\n",
    "\n",
    "import h5py\n",
    "from ImageAnalysis3.classes import _allowed_kwds\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10896a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44e6fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Folder Names: (ia.get_img_info.get_folders)\n",
      "- Number of folders: 12\n",
      "- Number of field of views: 161\n"
     ]
    }
   ],
   "source": [
    "data_folder = r'\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors'\n",
    "\n",
    "folders, fovs = ia.io_tools.data.get_folders(data_folder)\n",
    "\n",
    "dapi_image_file = os.path.join(data_folder, 'H0M1', 'Conv_zscan_001.dax')\n",
    "#dapi_im = visual_tools.DaxReader(dapi_image_file).loadAll()[3::4][0::4]\n",
    "#dapi_im = im[3::4]#[::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b168214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flip_horizontal': False,\n",
       " 'flip_vertical': True,\n",
       " 'transpose': True,\n",
       " 'microns_per_pixel': 0.108}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_folder = r'\\\\10.245.74.158\\Chromatin_NAS_0\\Corrections\\20210621-Corrections_lumencor_from_60_to_50'\n",
    "\n",
    "segmentation_save_folder = os.path.join(data_folder, 'Segmentation')\n",
    "if not os.path.exists(segmentation_save_folder):\n",
    "    os.makedirs(segmentation_save_folder)\n",
    "from cellpose import models\n",
    "\n",
    "from ImageAnalysis3.segmentation_tools.cell import Align_Segmentation\n",
    "reload(ia.segmentation_tools.cell)\n",
    "\n",
    "# transpose with microscope\n",
    "microscope_file = r'\\\\mendel\\pu_documents\\Merfish_analysis\\Merfish_Analysis_Scripts\\merlin_parameters\\microscope\\storm6_microscope.json'\n",
    "microscope_params = Align_Segmentation._read_microscope_json(microscope_file)\n",
    "microscope_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910003e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_001.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_001.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_001.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 3.884s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.988s.\n",
      "-- corrected illumination for channel 488 in 8.040s.\n",
      "-- corrected illumination for channel 405 in 7.735s.\n",
      "- Finished illumination correction in 24.031s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_001.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 1.156s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 2.031s.\n",
      "-- corrected illumination for channel 488 in 2.031s.\n",
      "- Finished illumination correction in 4.219s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [-0.07 -8.36  3.01] in 0.828s.\n",
      "-- drift 1: [-0.1  -8.12  2.99] in 0.828s.\n",
      "-- drift 2: [-0.08 -8.04  3.15] in 0.844s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[-0.08333333 -8.17333333  3.05      ] for channel: 750\n",
      "-- finish warpping channel 750 in 21.782s.\n",
      "488 False True\n",
      "-- warp image with drift:[-0.08333333 -8.17333333  3.05      ] for channel: 488\n",
      "-- finish warpping channel 488 in 22.047s.\n",
      "-- finish warpping in 43.829s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 54.908s.\n",
      "(13, 2048, 2048) 1\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_1.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_002.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_002.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_002.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 3.860s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.625s.\n",
      "-- corrected illumination for channel 488 in 7.734s.\n",
      "-- corrected illumination for channel 405 in 7.986s.\n",
      "- Finished illumination correction in 23.596s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_002.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 0.756s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 1.967s.\n",
      "-- corrected illumination for channel 488 in 1.969s.\n",
      "- Finished illumination correction in 4.094s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [ -0.14 -12.33   2.19] in 0.844s.\n",
      "-- drift 1: [ -0.13 -12.12   2.32] in 0.828s.\n",
      "-- drift 2: [ -0.21 -12.21   2.28] in 0.859s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[ -0.16       -12.22         2.26333333] for channel: 750\n",
      "-- finish warpping channel 750 in 21.657s.\n",
      "488 False True\n",
      "-- warp image with drift:[ -0.16       -12.22         2.26333333] for channel: 488\n",
      "-- finish warpping channel 488 in 22.063s.\n",
      "-- finish warpping in 43.720s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 55.689s.\n",
      "(13, 2048, 2048) 2\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_2.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_003.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_003.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_003.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 6.188s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.894s.\n",
      "-- corrected illumination for channel 488 in 8.154s.\n",
      "-- corrected illumination for channel 405 in 7.750s.\n",
      "- Finished illumination correction in 24.032s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_003.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 0.891s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 1.969s.\n",
      "-- corrected illumination for channel 488 in 1.953s.\n",
      "- Finished illumination correction in 4.078s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [-0.13 -8.45 -1.33] in 0.828s.\n",
      "-- drift 1: [ -0.37 -91.92 240.1 ] in 0.844s.\n",
      "-- drift 2: [-0.13 -8.46 -1.24] in 0.859s.\n",
      "-- drift 3: [-0.12 -8.54 -1.27] in 0.828s.\n",
      "-- drift 4: [-0.18 -8.41 -1.06] in 0.828s.\n",
      "-- drift 5: [-0.13 -8.45 -1.28] in 0.844s.\n",
      "-- drift 6: [-0.2  -8.55 -1.4 ] in 0.859s.\n",
      "-- drift 7: [-0.12 -8.37 -1.25] in 0.844s.\n",
      "-- return a sub-optimal drift\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[-0.13       -8.45333333 -1.28333333] for channel: 750\n",
      "-- finish warpping channel 750 in 21.922s.\n",
      "488 False True\n",
      "-- warp image with drift:[-0.13       -8.45333333 -1.28333333] for channel: 488\n",
      "-- finish warpping channel 488 in 21.985s.\n",
      "-- finish warpping in 43.923s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 55.205s.\n",
      "(13, 2048, 2048) 3\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_3.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_004.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_004.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_004.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 6.078s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- corrected illumination for channel 750 in 7.875s.\n",
      "-- corrected illumination for channel 488 in 7.922s.\n",
      "-- corrected illumination for channel 405 in 7.687s.\n",
      "- Finished illumination correction in 23.735s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_004.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 0.781s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 2.031s.\n",
      "-- corrected illumination for channel 488 in 2.031s.\n",
      "- Finished illumination correction in 4.219s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [-0.05 -9.91  4.89] in 0.828s.\n",
      "-- drift 1: [-0.06 -9.92  5.16] in 0.844s.\n",
      "-- drift 2: [-0.06 -9.82  5.01] in 0.828s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[-0.05666667 -9.88333333  5.02      ] for channel: 750\n",
      "-- finish warpping channel 750 in 21.829s.\n",
      "488 False True\n",
      "-- warp image with drift:[-0.05666667 -9.88333333  5.02      ] for channel: 488\n",
      "-- finish warpping channel 488 in 22.001s.\n",
      "-- finish warpping in 43.829s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 55.174s.\n",
      "(13, 2048, 2048) 4\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_4.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_005.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_005.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_005.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 3.875s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.952s.\n",
      "-- corrected illumination for channel 488 in 7.922s.\n",
      "-- corrected illumination for channel 405 in 7.797s.\n",
      "- Finished illumination correction in 23.907s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_005.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 1.797s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 2.031s.\n",
      "-- corrected illumination for channel 488 in 1.953s.\n",
      "- Finished illumination correction in 4.249s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [-0.07 -8.99  1.28] in 0.844s.\n",
      "-- drift 1: [-0.06 -9.    1.42] in 0.828s.\n",
      "-- drift 2: [-0.09 -8.76  1.25] in 0.844s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[-0.07333333 -8.91666667  1.31666667] for channel: 750\n",
      "-- finish warpping channel 750 in 21.876s.\n",
      "488 False True\n",
      "-- warp image with drift:[-0.07333333 -8.91666667  1.31666667] for channel: 488\n",
      "-- finish warpping channel 488 in 22.189s.\n",
      "-- finish warpping in 44.065s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 61.127s.\n",
      "(13, 2048, 2048) 5\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_5.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_006.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_006.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_006.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 3.641s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.860s.\n",
      "-- corrected illumination for channel 488 in 8.047s.\n",
      "-- corrected illumination for channel 405 in 7.782s.\n",
      "- Finished illumination correction in 23.969s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_006.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 0.953s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 1.954s.\n",
      "-- corrected illumination for channel 488 in 1.984s.\n",
      "- Finished illumination correction in 4.125s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [-0.04 -6.79 -0.37] in 0.828s.\n",
      "-- drift 1: [-0.08 -6.7  -0.26] in 0.844s.\n",
      "-- drift 2: [-0.07 -6.62 -0.46] in 0.844s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[-0.06333333 -6.70333333 -0.36333333] for channel: 750\n",
      "-- finish warpping channel 750 in 21.938s.\n",
      "488 False True\n",
      "-- warp image with drift:[-0.06333333 -6.70333333 -0.36333333] for channel: 488\n",
      "-- finish warpping channel 488 in 21.985s.\n",
      "-- finish warpping in 43.923s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 56.204s.\n",
      "(13, 2048, 2048) 6\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_6.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_007.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_007.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_007.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 6.374s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.860s.\n",
      "-- corrected illumination for channel 488 in 8.064s.\n",
      "-- corrected illumination for channel 405 in 7.796s.\n",
      "- Finished illumination correction in 23.953s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_007.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 0.861s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 1.972s.\n",
      "-- corrected illumination for channel 488 in 1.984s.\n",
      "- Finished illumination correction in 4.125s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- drift 0: [-0.04 -7.78  0.99] in 0.844s.\n",
      "-- drift 1: [-0.05 -7.79  1.14] in 0.828s.\n",
      "-- drift 2: [-0.05 -7.81  1.01] in 0.828s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[-0.04666667 -7.79333333  1.04666667] for channel: 750\n",
      "-- finish warpping channel 750 in 22.000s.\n",
      "488 False True\n",
      "-- warp image with drift:[-0.04666667 -7.79333333  1.04666667] for channel: 488\n",
      "-- finish warpping channel 488 in 22.094s.\n",
      "-- finish warpping in 44.095s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 55.891s.\n",
      "(13, 2048, 2048) 7\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_7.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_008.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_008.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_008.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 4.359s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.906s.\n",
      "-- corrected illumination for channel 488 in 7.922s.\n",
      "-- corrected illumination for channel 405 in 7.609s.\n",
      "- Finished illumination correction in 23.704s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_008.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 1.391s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 1.969s.\n",
      "-- corrected illumination for channel 488 in 1.969s.\n",
      "- Finished illumination correction in 4.094s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [-0.04 -7.39 -4.59] in 0.828s.\n",
      "-- drift 1: [-0.07 -7.49 -5.35] in 0.828s.\n",
      "-- drift 2: [-0.09 -7.45 -5.24] in 0.859s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[-0.06666667 -7.44333333 -5.06      ] for channel: 750\n",
      "-- finish warpping channel 750 in 21.641s.\n",
      "488 False True\n",
      "-- warp image with drift:[-0.06666667 -7.44333333 -5.06      ] for channel: 488\n",
      "-- finish warpping channel 488 in 21.985s.\n",
      "-- finish warpping in 43.626s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 56.189s.\n",
      "(13, 2048, 2048) 8\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_8.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_009.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_009.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_009.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 3.562s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.891s.\n",
      "-- corrected illumination for channel 488 in 7.938s.\n",
      "-- corrected illumination for channel 405 in 7.641s.\n",
      "- Finished illumination correction in 23.704s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_009.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 0.922s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 2.051s.\n",
      "-- corrected illumination for channel 488 in 2.031s.\n",
      "- Finished illumination correction in 4.258s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [-0.07 -8.34  0.79] in 0.861s.\n",
      "-- drift 1: [-0.05 -8.12  0.89] in 0.858s.\n",
      "-- drift 2: [-0.08 -8.11  0.86] in 0.844s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[-0.06666667 -8.19        0.84666667] for channel: 750\n",
      "-- finish warpping channel 750 in 21.641s.\n",
      "488 False True\n",
      "-- warp image with drift:[-0.06666667 -8.19        0.84666667] for channel: 488\n",
      "-- finish warpping channel 488 in 21.953s.\n",
      "-- finish warpping in 43.595s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 56.954s.\n",
      "(13, 2048, 2048) 9\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_9.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_010.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_010.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_010.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n",
      "- Loaded images for channels:['750', '488', '405'] in 4.254s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.898s.\n",
      "-- corrected illumination for channel 488 in 8.234s.\n",
      "-- corrected illumination for channel 405 in 7.688s.\n",
      "- Finished illumination correction in 24.030s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_010.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 1.641s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 1.969s.\n",
      "-- corrected illumination for channel 488 in 1.985s.\n",
      "- Finished illumination correction in 4.297s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [ -0.09 -13.66   0.35] in 0.859s.\n",
      "-- drift 1: [ -0.06 -13.44   0.61] in 0.859s.\n",
      "-- drift 2: [ -0.07 -13.26   0.61] in 0.890s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[ -0.07333333 -13.45333333   0.52333333] for channel: 750\n",
      "-- finish warpping channel 750 in 22.172s.\n",
      "488 False True\n",
      "-- warp image with drift:[ -0.07333333 -13.45333333   0.52333333] for channel: 488\n",
      "-- finish warpping channel 488 in 22.032s.\n",
      "-- finish warpping in 44.204s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation in 56.985s.\n",
      "(13, 2048, 2048) 10\n",
      "- save to file: \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\Segmentation\\segmentation_label_10.npy\n",
      "\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_011.dax \\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_011.dax\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H0M1\\Conv_zscan_011.dax\n",
      "-- all used channels: ['750', '647', '488', '405']\n",
      "-- single image size: [  50 2048 2048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded images for channels:['750', '488', '405'] in 5.656s.\n",
      "- Start illumination correction for channels:['750', '488', '405'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "\t 405 illumination_correction_405_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 7.750s.\n",
      "-- corrected illumination for channel 488 in 7.891s.\n",
      "-- corrected illumination for channel 405 in 7.938s.\n",
      "- Finished illumination correction in 23.845s.\n",
      "Initialize DaxProcesser for file:\\\\10.245.74.158\\Chromatin_NAS_0\\20220329-P_brain_M1_nonclear_adaptors\\H11M12\\Conv_zscan_011.dax\n",
      "-- all used channels: ['750', '647', '488']\n",
      "-- single image size: [  13 2048 2048]\n",
      "- Loaded images for channels:['750', '488'] in 0.844s.\n",
      "- Start illumination correction for channels:['750', '488'].\n",
      "-- loading illumination correction profile from file:\n",
      "\t 750 illumination_correction_750_2048x2048.npy\n",
      "\t 488 illumination_correction_488_2048x2048.npy\n",
      "-- corrected illumination for channel 750 in 2.156s.\n",
      "-- corrected illumination for channel 488 in 2.047s.\n",
      "- Finished illumination correction in 4.343s.\n",
      "+ Calculate drift with drift_channel: 488\n",
      "-- start aligning given source image to given reference image.\n",
      "-- drift 0: [-0.03 -7.7   2.09] in 0.844s.\n",
      "-- drift 1: [-0.02 -7.57  2.18] in 0.828s.\n",
      "-- drift 2: [-0.04 -7.64  2.12] in 0.844s.\n",
      "--- drifts for crops:[0 1 2] pass the thresold, exit cycle.\n",
      "- Start warpping images channels:['750', '488'].\n",
      "750 False False\n",
      "-- warp image with drift:[-0.03       -7.63666667  2.13      ] for channel: 750\n",
      "-- finish warpping channel 750 in 21.985s.\n",
      "488 False True\n",
      "-- warp image with drift:[-0.03       -7.63666667  2.13      ] for channel: 488\n",
      "-- finish warpping channel 488 in 22.125s.\n",
      "-- finish warpping in 44.110s.\n",
      "- apply microscope corrections\n",
      "- run Cellpose segmentation "
     ]
    }
   ],
   "source": [
    "\n",
    "for _fov_id, _fov_name in enumerate(fovs):\n",
    "    \n",
    "    seg_save_file = os.path.join(segmentation_save_folder, f'segmentation_label_{_fov_id}.npy')\n",
    "    if os.path.exists(seg_save_file):\n",
    "        continue\n",
    "\n",
    "    dapi_image_file = os.path.join(folders[0], _fov_name)\n",
    "    polyt_image_file = os.path.join(folders[-1], _fov_name)\n",
    "    print(dapi_image_file, polyt_image_file)\n",
    "    # load reference DAPI\n",
    "    _ref_cls = ia.classes.preprocess.DaxProcesser(dapi_image_file, \n",
    "                                                 CorrectionFolder=correction_folder, DriftChannel=488, DapiChannel=405)\n",
    "    _ref_cls._load_image(sel_channels=[750,488,405])\n",
    "    _ref_cls._corr_illumination()\n",
    "    _ref_im = _ref_cls.im_488[0::4]\n",
    "    # load polyT\n",
    "    _cls = ia.classes.preprocess.DaxProcesser(polyt_image_file, \n",
    "                                              CorrectionFolder=correction_folder, DriftChannel=488, DapiChannel=405)\n",
    "    _cls._load_image(sel_channels=[750,488])\n",
    "    _cls._corr_illumination()\n",
    "    _cls._calculate_drift(_ref_im)\n",
    "    _cls._warp_image(corr_chromatic=False)\n",
    "    # cellpose\n",
    "    print(f\"- apply microscope corrections\")\n",
    "    test_dapi_im = Align_Segmentation._correct_image3D_by_microscope_param(_ref_cls.im_405[0::4], microscope_params)\n",
    "    test_polyt_im = Align_Segmentation._correct_image3D_by_microscope_param(_cls.im_750, microscope_params)\n",
    "    \n",
    "    print(f\"- run Cellpose segmentation\", end=' ')\n",
    "    _cellpose_start = time.time()\n",
    "    test_dapi_im = np.array([cv2.resize(_ly, (1024,1024) ) for _ly in test_dapi_im])\n",
    "    test_polyt_im = np.array([cv2.resize(_ly, (1024,1024) ) for _ly in test_polyt_im])\n",
    "\n",
    "    seg_model = models.CellposeModel(gpu=True, model_type='TN2')\n",
    "\n",
    "    labels3d, _, _ = seg_model.eval(np.stack([test_polyt_im, test_dapi_im], axis=3), \n",
    "                                    batch_size=20, anisotropy=1000/108/2,\n",
    "                                    cellprob_threshold=0, \n",
    "                                    channels=[1,2], diameter=30, min_size=100,\n",
    "                                    do_3D=True,\n",
    "                                    )\n",
    "\n",
    "    print(f\"in {time.time()-_cellpose_start:.3f}s.\")\n",
    "    \n",
    "    \n",
    "    # resize segmentation label back\n",
    "    labels3d = np.array([cv2.resize(_ly, _cls.im_750.shape[1:], \n",
    "                                    interpolation=cv2.INTER_NEAREST_EXACT) \n",
    "                         for _ly in labels3d])\n",
    "\n",
    "    \n",
    "    print(labels3d.shape, _fov_id)\n",
    "    # save this segmentation mask\n",
    "    print(f\"- save to file: {seg_save_file}\")\n",
    "    np.save(seg_save_file.split('.npy')[0], labels3d, )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce18db02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fde6ecc",
   "metadata": {},
   "source": [
    "## Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33da5ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"399.9999913302337\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ImageAnalysis3.visual_tools.imshow_mark_3d_v2 at 0x240590f8ca0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_tools.imshow_mark_3d_v2([_ref_cls.im_405, _cls.im_750, labels3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453f5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia3_postanalysis",
   "language": "python",
   "name": "ia3_postanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
